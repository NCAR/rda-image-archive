{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "*We'll set up a working directory and download a small sample\n",
    "of images to ingest.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "50"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# We create a working directory for this example.\n",
    "os.makedirs(\"00_files\", exist_ok=True)\n",
    "\n",
    "# We create a \"data\" subdirectory for the images and the metadata tag files.\n",
    "os.makedirs(\"00_files\", exist_ok=True)\n",
    "data = \"00_files/data\"\n",
    "\n",
    "# We create an \"out\" subdirectory for the processed images and the metadata catalog.\n",
    "os.makedirs(\"00_files/out\", exist_ok=True)\n",
    "out  = \"00_files/out\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download a sample collection of 20 images from the logbooks of the USCG\n",
    "Storis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "51"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import logging\n",
    "import http.client\n",
    "\n",
    "# To set up logging.\n",
    "# https://stackoverflow.com/questions/16337511/\n",
    "http.client.HTTPConnection.debuglevel = 1\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "requests_log = logging.getLogger(\"requests.packages.urllib3\")\n",
    "requests_log.setLevel(logging.DEBUG)\n",
    "requests_log.propagate = True\n",
    "\n",
    "# To access the NARA API for images of the USCG Storis' 1957 logbook.\n",
    "nara_id = \"38547962\"\n",
    "api_base = 'https://catalog.archives.gov/api/v1/'\n",
    "api_url = '{0}?naIds={1}'.format(api_base, nara_id)\n",
    "res = requests.get(api_url)\n",
    "\n",
    "# To parse the NARA API output for metadata.\n",
    "entry_img_array = res.json().get('opaResponse').get('results').get('result')[0].get('objects').get('object')\n",
    "digital_directory = entry_img_array[0].get('file').get('@path').split(\"/\")[-2]\n",
    "\n",
    "# To write the NARA API output to file for reference.\n",
    "api_output = \"{0}/nara_id_{1}.json\".format(data, digital_directory, nara_id)\n",
    "if res.status_code == 200:\n",
    "    with open(api_output, 'wb') as f:\n",
    "        f.write(res.content)\n",
    "\n",
    "# To download images of 40 pages of the Storis' logbooks.\n",
    "for img_info in entry_img_array: \n",
    "\n",
    "    # We test for mimetype \"image/jpeg\"---we don't want to download any files\n",
    "    # with mimetype \"application/pdf\".\n",
    "    if img_info.get('file').get('@mime') == \"image/jpeg\":\n",
    "\n",
    "        img_name = img_info.get('file').get('@name')\n",
    "        img_url = img_info.get('file').get('@url')\n",
    "        img_res = requests.get(img_url)\n",
    "\n",
    "        # To write a single image to file.\n",
    "        local_img_name = \"{0}/{1}\".format(data, img_name)\n",
    "        if img_res.status_code == 200:\n",
    "            with open(local_img_name, 'wb') as img_f:\n",
    "                img_f.write(img_res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a metadata tagfile in the \"data\" subdirectory with the minimal\n",
    "required metadata for the sample of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "52"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(os.path.join(data, 'metadata.csv'), mode='w') as metadata_file:\n",
    "    metadata_writer = csv.writer(metadata_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    metadata_writer.writerow(['archive.host_country', 'USA'])\n",
    "    metadata_writer.writerow(['document.contact_person', 'Kevin Wood'])\n",
    "    metadata_writer.writerow(['archive.notes', 'Images available via API at https://catalog.archives.gov/api/v1/38547962'])\n",
    "    metadata_writer.writerow(['platform.name', 'USCG Storis'])\n",
    "    metadata_writer.writerow(['document.id_within_archive', '38547962'])\n",
    "    metadata_writer.writerow(['document.id_within_archive_type', 'NARA ID'])\n",
    "    metadata_writer.writerow(['document.record_type', \"ships' logs\"])\n",
    "    metadata_writer.writerow(['document.accession_to_archive_date', '2016-08-19'])\n",
    "    metadata_writer.writerow(['document.standardized_region_list', 'north_atlantic'])\n",
    "    metadata_writer.writerow(['document.start_date', '1957-06-09'])\n",
    "    metadata_writer.writerow(['document.start_date', '1957-09-30'])\n",
    "    metadata_writer.writerow(['document.rights_statement', 'CC0 Public Domain'])\n",
    "    metadata_writer.writerow(['document.notes', ''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During ingest we'll associate the above metadata to the 20 samples images. In\n",
    "practice, any `.csv` file in the `data` subdirectory will be parsed as a\n",
    "metadata tagefile. For example, the tagfile `metadata.csv` provides metadata for\n",
    "images in the same directory `uscg-storis/data` as itself and in all\n",
    "subdirectory below itself. \n",
    "\n",
    "To enable users to provide \"hierarchical\" metadata,\n",
    "the information in a tagfile from a subdirectory has precendence over any\n",
    "tagfiles from parent directories. (The idea is to provide the *most specific\n",
    "metadata* for images in the same directory as the images themselves, while\n",
    "parent directories might provide *general metadata* for a whole collection of\n",
    "images.)\n",
    "\n",
    "Here's what the tagfile we created looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "53"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(os.path.join(data, \"metadata.csv\"), header=None, names=[\"field\", \"value\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingesting images\n",
    "\n",
    "First, we'll interactively load \"helper\" functions as defined in the `rdai`\n",
    "module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "57"
    }
   },
   "outputs": [],
   "source": [
    "%run -i rdai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll define the global variable `fixed_seq` in order to call `mint_uuid`\n",
    "for each image file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "55"
    }
   },
   "outputs": [],
   "source": [
    "# We generate a fixed sequence for uuids.\n",
    "get_fixed_seq()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're on casper, then we'll need to load python-magic from `rdadata`. Else,\n",
    "we assume the python-magic package has already been installed, e.g., with `pip3\n",
    "install python-magic --user`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "58"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/glade/u/home/rdadata/lib/python/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "66"
    }
   },
   "outputs": [],
   "source": [
    "# get_exiftool()\n",
    "import subprocess\n",
    "repo_dir = subprocess.Popen(['git', 'rev-parse', '--show-toplevel'], stdout=subprocess.PIPE).communicate()[0].rstrip().decode('utf-8')\n",
    "import sys\n",
    "sys.path.append(os.path.join(repo_dir, \"dependencies/pyexiftool\"))\n",
    "import exiftool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "67"
    }
   },
   "outputs": [],
   "source": [
    "normalized_catalog = get_normalized_catalog(data)\n",
    "# We generate a metadata catalog (unnormalized) from the data directory.\n",
    "\n",
    "catalog = unnormalize_catalog(normalized_catalog)\n",
    "# We flatten the normalized catalog. \n",
    "# Each file in the data directory \"has its own entry\" in this catalog.\n",
    "# We'll eventually ignore non-image files.\n",
    "\n",
    "write_timestamped_catalog(catalog, out)\n",
    "# We write this version of the metadata catalog to the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "68"
    }
   },
   "outputs": [],
   "source": [
    "catalog = read_timestamped_catalog(out)\n",
    "# We read in the most recent version of the metadata catalog from the out directory.\n",
    "\n",
    "elementary_family = [c for c in catalog if c['media_type'].startswith(\"image\")]\n",
    "# We create a list of all the entries in the catalog that are image files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "69"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# We'll perform some file renames between the data directory and the out directory.\n",
    "\n",
    "# We move all the images in the catalog to the output directory.\n",
    "for member in elementary_family:\n",
    "    os.rename(member['file_path'], os.path.join(out, member['uuid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "71"
    }
   },
   "outputs": [],
   "source": [
    "# Conversely, we move all the images in the catalog back to the data directory.\n",
    "for member in elementary_family:\n",
    "    os.rename(os.path.join(out, member['uuid']), member['file_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "72"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '00_files/': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm -r 00_files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
